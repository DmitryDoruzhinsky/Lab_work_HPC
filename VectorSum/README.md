# VectorSum
После распоралеллевания каждая нить в зависимости от своего id работает с разными элементами и суммируют их. При перезаписывание переменной хранящей результирующее выражение, происходит блокировка переменной с помощью функции atomic (*numba.cuda*), для того, чтобы избежать ситуации, когда несколько потоков захотят изменить одну и ту же переменную.

Были получены следующие результаты:<\br>
![image](https://user-images.githubusercontent.com/83270014/211028524-18196869-efe7-443b-a299-b6a200cd6d08.png)
![image](https://user-images.githubusercontent.com/83270014/211028550-b4eef95a-105c-42a5-bfc2-ec20703e3f19.png)
Первое значение времени выполнение на GPU выбивается из общей картины, возможно причиной этому служит задержка перед передачей данных GoogleColab. <\br>
Так же при данных значениях размерности векторов можно увидеть, что сильного прироста в производительности не наблюдается. Моё мнение, что имеет смысл применять CUDA для суммирования элементов вектора при рахмерности более 1 млрд, хотя нужно ещё придумать такую задачу. <\br>
Так же из-за проведения эксперимента на разных устройствах подсчёт ускорения не имеет смысла, так как значения затраченного времени очень малы.

Код для вычисления на CPU находится в файле *Vector_Sum_CPU.ipynb*. </br>
Код для вычесления на GPU находится на [Google Drive](https://colab.research.google.com/drive/1bsC4f8GGWNZRWALz3H9h7z2QKsPqnfRh#scrollTo=aC4rG8w8WKFq).
